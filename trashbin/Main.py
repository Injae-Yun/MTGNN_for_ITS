import os
import yaml
import numpy as np
import pandas as pd
import pickle
import glob
import psycopg2
import time
import shutil

from Utils.logger import get_logger
from Utils.get_focus_timepoints import get_focus_timepoints
from Utils.Preprocess_data import (
    process_day_to_linkwise, 
    build_cluster_tensor,
    build_cluster_y_tensor,
    build_cluster_y_tensor_optimized,
    process_raw_to_cluster_tensor,
    process_raw_to_cluster_tensor_h5
)
from Utils.Preprocess_fast import (
    process_raw_to_cluster_tensor_pivot,
    process_predict_to_cluster_tensor_pivot,
)
from Script.Dataloader_DB import load_from_mongo
from Script.Tester import (
    Predictor,
    Make_Test_results,
)
from Utils.share import Make_Postgres_form
from Script import Trainer
from Core.Train_MTGNN import training_MTGNN
import sys
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

def load_config(config_path):
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def load_link_ids(model_version: str, cluster_id: str) -> list:
    """
    ëª¨ë¸ ë²„ì „ ë° í´ëŸ¬ìŠ¤í„° IDì— ë”°ë¼ LINK_ID ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜´
    ì˜ˆ: Model/v3.2.1/cluster_001/link_ids.txt
    """
    file_path = os.path.join("Model", model_version, f"cluster_{cluster_id:03}", "link_ids.txt")
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"âŒ link_ids íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
    return np.loadtxt(file_path, dtype=str).tolist()

def clear_parquet_files(processed_dir):
    parquet_files = glob.glob(os.path.join(processed_dir, "*"))
    for file_path in parquet_files:
        if os.path.isfile(file_path):
            os.remove(file_path)
        elif os.path.isdir(file_path):
            # ë””ë ‰í„°ë¦¬ê°€ ë¹„ì–´ ìˆìœ¼ë©´
            try:
                os.rmdir(file_path)
            except OSError:
                # ë¹„ì–´ ìˆì§€ ì•Šë‹¤ë©´ í•˜ìœ„ í¬í•¨ ì „ë¶€ ì‚­ì œ
                shutil.rmtree(file_path)


def main(mode="train",version='v1.0.0',
         config_name='Livinglab_test.yaml',
         course=[0,0,0,0],db_name='Mongo_db'):
    # 0. link list ë¶ˆëŸ¬ì˜¤ê³ , mongo DBì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    Model_version = 'v'+str(version[1])  # 'v3'ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ â†’ 3
    db_yaml = db_name+'.yaml'  # MongoDB ì ‘ì† ì •ë³´ íŒŒì¼
    Model_yaml = 'MTGNN_config.yaml'
    # 1. ë¡œê¹… ë° ì¶œë ¥ ê²½ë¡œ ì„¤ì •
    logger = get_logger()
    output_dir_raw = os.path.join("Data", "Raw")
    output_dir_processed = os.path.join("Data", "Processed")
    output_dir_model = os.path.join("Model", Model_version)
    Config_path = os.path.join("Config" ,Model_yaml)

    # 2. Config ë¡œë“œ
    mongo_config = load_config(os.path.join("Config" ,db_yaml))
    task_config = load_config(os.path.join('Config',config_name))
    path_config = load_config(os.path.join('Config','Data_path_config.yaml'))
    dates,time_points=get_focus_timepoints(task_config,logger)
    target = task_config['target']  # 'Korea' ë˜ëŠ” 'Livinglab'


    link_ids = np.loadtxt(os.path.join('Data',target,'Link.txt'), dtype=str)
    cluster_path = os.path.join('Data',target ,'expanded_clusters.pkl')
    with open(cluster_path, "rb") as f:
        clusters = pickle.load(f) #cluster information
    sorted_clusters = dict(sorted(clusters.items(), key=lambda x: x[0]))  # key ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬

    # 4. MongoDBì—ì„œ ë°ì´í„° ë¡œë“œ ë° ì €ì¥
    if course[0] == 0 :
        if db_name == 'Mongo_db':
            projection=task_config['projection']
            load_from_mongo(link_ids, dates,time_points,projection, mongo_config, output_dir_raw,target, logger)
            logger.info(f"âœ… Data load ì™„ë£Œ: ì´ {len(dates)}ê°œ íŒŒì¼ ì €ì¥ë¨")
        else:
            logger.info(f"Error: other DB is not supported")
            exit()
    else: 
        logger.info(f"âœ… Data load skip: ì´ {len(dates)}ê°œ íŒŒì¼ ì €ì¥ë¨")

# ë°ì´í„° ì „ì²˜ë¦¬ ìˆ˜í–‰
    # Make processed data 
    if course[1] == 0:
        logger.info(f"ğŸ”¹ pivot ë°©ë²•: Raw â†’ í´ëŸ¬ìŠ¤í„° í…ì„œ (ê³ ì†Â·ì €ë©”ëª¨ë¦¬)")
        if mode == "predict":
                    # 1) ë¹ ë¥¸ í”¼ë²— ê¸°ë°˜ ì˜ˆì¸¡ ì…ë ¥ ìƒì„± (predict_data.npy + timestamp)
            timestamp = process_predict_to_cluster_tensor_pivot(
                output_dir_raw, sorted_clusters, path_config, task_config, output_dir_model, logger
            )
            logger.info(f"âœ… Raw ë°ì´í„°ì—ì„œ predict í´ëŸ¬ìŠ¤í„° í…ì„œ ìƒì„± ì™„ë£Œ: {output_dir_model}ì— ì €ì¥ë¨")
        else: 
            # H5 ë°©ë²•: Rawì—ì„œ ë°”ë¡œ í´ëŸ¬ìŠ¤í„° í…ì„œë¡œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
            timestamp = process_raw_to_cluster_tensor_pivot(
                output_dir_raw, sorted_clusters, path_config,
                task_config, output_dir_model, logger, generate_y=True
            )
            logger.info(f"âœ… Raw ë°ì´í„°ì—ì„œ train/val/test í´ëŸ¬ìŠ¤í„° í…ì„œ ìƒì„± ì™„ë£Œ: {output_dir_model}ì— ì €ì¥ë¨")


    else: 
        timestamp = np.load(os.path.join(output_dir_processed, 'timestamp.npy'))
        logger.info(f"âœ… ë°ì´í„° ì „ì²˜ë¦¬ skip: {output_dir_model}ì— ì €ì¥ë¨")
    
    if mode == "train":
        # make map for MTGNN

        if course[2] == 0 :
            Trainer.genmap(link_ids,sorted_clusters,target,path_config,logger)#cluster_id
        else:
            logger.info(f"âœ… map í˜•ì„± skip")
        training_MTGNN(Config_path, output_dir_model, sorted_clusters,target, logger, cluster_id=None )

    elif mode == "test":
        #ì´ë•Œ trainì´ ì•„ë‹ˆë¼ë©´, ê° ë°ì´í„°ì…‹ì„ testìš©ë„ë¡œë§Œ ì •ë¦¬
        tic=time.time()
        Predict_result=Make_Test_results(output_dir_model,sorted_clusters,logger) #cluster_id=None
        toc=time.time()
        print(f"Time taken: {toc-tic} seconds")

    elif mode == "predict":
        #ì´ë•Œ trainì´ ì•„ë‹ˆë¼ë©´, ê° ë°ì´í„°ì…‹ì„ testìš©ë„ë¡œë§Œ ì •ë¦¬
        tic=time.time()
        # 2) ì˜ˆì¸¡ ì‹¤í–‰
        Predict_result=Predictor(output_dir_model,sorted_clusters,task_config,logger) #cluster_id=None
        toc=time.time()
        print(f"Time taken: {toc-tic} seconds")
        conn = psycopg2.connect(**task_config['Postgres_info'])
        Make_Postgres_form(timestamp,Predict_result,conn,path_config, task_config,logger)


if __name__ == "__main__":
    #main(mode="train",version='v1.0.0')
    """
    config_name = "Korea_train.yaml"
    target = 'Korea'
    course= [1, 1, 1, 1, 1 ]
    main(mode="train",version='v0.0.0',config_name=config_name,target=target,course=course) #v0 ìœ„ì¹˜ì— ëª¨ë¸ ì €ì¥
    # config_name = "Livinglab_test.yaml"
    # target= 'Livinglab'
    # main(mode="train",version='v0.0.0',config_name=config_name,target=target) #v0 ìœ„ì¹˜ì— ëª¨ë¸ ì €ì¥
    """
    config_name = "Livinglab_test.yaml"
    db_name = 'Mongo_db'
    course= [1, 1, 1] # 1 = skip, course[1]=0, course[2]=0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìµœì í™”ëœ ë°©ë²• í…ŒìŠ¤íŠ¸
    tic=time.time()
    main(mode="predict",version='v0.0.0',config_name=config_name,course=course,db_name=db_name) #v0 ìœ„ì¹˜ì— ëª¨ë¸ ì €ì¥
    toc=time.time()
    print(f"Time taken: {toc-tic} seconds")
    